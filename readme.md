# Run LLM Locally with Ollama

Download and install olama from https://ollama.com/

## Models
Download following models for 2 step search

* ollama pull llama3.2:1b
* ollama pull mxbai-embed-large:335m

## Install dependencies
`pip install -r ./requirements.txt`

## Run
`streamlit run main.py`
